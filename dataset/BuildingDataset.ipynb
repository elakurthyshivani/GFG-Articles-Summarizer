{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Install packages if not yet installed**"
      ],
      "metadata": {
        "id": "NSQ-wgPYo5-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install bs4 # BeautifulSoup\n",
        "!{sys.executable} -m pip install opendatasets # OpenDatasets\n",
        "!{sys.executable} -m pip install azure.storage.blob # Azure Blob Storage\n",
        "!{sys.executable} -m pip install azure-cosmos # Azure Cosmos DB"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: bs4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from bs4) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.4.1)\nRequirement already satisfied: opendatasets in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (0.1.22)\nRequirement already satisfied: kaggle in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opendatasets) (1.5.16)\nRequirement already satisfied: click in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opendatasets) (8.1.3)\nRequirement already satisfied: tqdm in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opendatasets) (4.66.1)\nRequirement already satisfied: certifi in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (2023.5.7)\nRequirement already satisfied: six>=1.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: urllib3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (1.26.16)\nRequirement already satisfied: python-slugify in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (8.0.1)\nRequirement already satisfied: python-dateutil in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (2.31.0)\nRequirement already satisfied: bleach in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from kaggle->opendatasets) (6.0.0)\nRequirement already satisfied: webencodings in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (3.1.0)\nRequirement already satisfied: azure.storage.blob in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (12.16.0)\nRequirement already satisfied: isodate>=0.6.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure.storage.blob) (0.6.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.26.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure.storage.blob) (1.27.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure.storage.blob) (4.6.3)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure.storage.blob) (41.0.1)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.26.0->azure.storage.blob) (1.16.0)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.26.0->azure.storage.blob) (2.31.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cryptography>=2.1.4->azure.storage.blob) (1.15.1)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure.storage.blob) (2.21)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (2023.5.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure.storage.blob) (3.1.0)\nRequirement already satisfied: azure-cosmos in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (4.5.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.23.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-cosmos) (1.27.1)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos) (4.6.3)\nRequirement already satisfied: requests>=2.18.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.23.0->azure-cosmos) (2.31.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos) (1.26.16)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos) (3.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-cosmos) (2023.5.7)\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wlAyi5eowBN",
        "outputId": "7de9caa1-05e8-43da-fefd-cf00f70159ba",
        "gather": {
          "logged": 1694445869464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reading the dataset**\n",
        "\n",
        "**1.** Create a file `kaggle.json` and save your Kaggle username and API key. This will be used to download the dataset from Kaggle.\n",
        "\n",
        "**2.** The URL of the dataset is [https://www.kaggle.com/datasets/ashishjangra27/geeksforgeeks-articles](https://www.kaggle.com/datasets/ashishjangra27/geeksforgeeks-articles \"GeeksForGeeks Articles Dataset\"). Using `opendatasets` package, download the dataset. Step 1 is required in order for this to automatically take in your username and API key.\n",
        "\n",
        "**3.** Read the downloaded dataset."
      ],
      "metadata": {
        "id": "0u_mKLnrrQDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import opendatasets as od\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "_HY149OvspXy",
        "gather": {
          "logged": 1694445873889
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating kaggle.json file.\n",
        "with open(\"kaggle.json\", \"w\") as kaggleFile:\n",
        "    kaggleFile.write(json.dumps({\"username\":\"shivanielakurthy\", \"key\":\"da7b4ae4bd1b770cb8b74d3990fc7f43\"}))"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "BwxV64rvrPQW",
        "gather": {
          "logged": 1694445874026
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset.\n",
        "od.download(\"https://www.kaggle.com/datasets/ashishjangra27/geeksforgeeks-articles\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading geeksforgeeks-articles.zip to ./geeksforgeeks-articles\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 1.31M/1.31M [00:00<00:00, 7.33MB/s]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYGBnqsLpf96",
        "outputId": "b9722636-93ec-4f7a-f3c3-df1b4976a274",
        "gather": {
          "logged": 1694445875577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the dataset.\n",
        "articles=pd.read_csv(r\"geeksforgeeks-articles/articles.csv\")\n",
        "articles.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                                          title         author_id  \\\n0        5 Best Practices For Writing SQL Joins       priyankab14   \n1                  Foundation CSS Dropdown Menu  ishankhandelwals   \n2  Top 20 Excel Shortcuts That You Need To Know       priyankab14   \n3                     Servlet – Fetching Result   nishatiwari1719   \n4                              Suffix Sum Array          rohit768   \n\n   last_updated                                               link category  \n0  21 Feb, 2022  https://www.geeksforgeeks.org/5-best-practices...     easy  \n1  20 Feb, 2022  https://www.geeksforgeeks.org/foundation-css-d...     easy  \n2  17 Feb, 2022  https://www.geeksforgeeks.org/top-20-excel-sho...     easy  \n3  17 Feb, 2022  https://www.geeksforgeeks.org/servlet-fetching...     easy  \n4  21 Feb, 2022    https://www.geeksforgeeks.org/suffix-sum-array/     easy  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author_id</th>\n      <th>last_updated</th>\n      <th>link</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5 Best Practices For Writing SQL Joins</td>\n      <td>priyankab14</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/5-best-practices...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Foundation CSS Dropdown Menu</td>\n      <td>ishankhandelwals</td>\n      <td>20 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/foundation-css-d...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Top 20 Excel Shortcuts That You Need To Know</td>\n      <td>priyankab14</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/top-20-excel-sho...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Servlet – Fetching Result</td>\n      <td>nishatiwari1719</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/servlet-fetching...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Suffix Sum Array</td>\n      <td>rohit768</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/suffix-sum-array/</td>\n      <td>easy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJZmKjR3pFJU",
        "outputId": "3e3d8b1d-ecf6-4aa7-d7fc-93ea4900a640",
        "gather": {
          "logged": 1694445875849
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(34574, 5)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445875995
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dropping rows with null values**"
      ],
      "metadata": {
        "id": "7XBDpD3v0wvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles=articles.dropna()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "id": "uFmwL_SBykL-",
        "gather": {
          "logged": 1694445876122
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset index.\n",
        "articles=articles.reset_index().drop(\"index\", axis=1)\n",
        "articles.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "                                          title         author_id  \\\n0        5 Best Practices For Writing SQL Joins       priyankab14   \n1                  Foundation CSS Dropdown Menu  ishankhandelwals   \n2  Top 20 Excel Shortcuts That You Need To Know       priyankab14   \n3                     Servlet – Fetching Result   nishatiwari1719   \n4                              Suffix Sum Array          rohit768   \n\n   last_updated                                               link category  \n0  21 Feb, 2022  https://www.geeksforgeeks.org/5-best-practices...     easy  \n1  20 Feb, 2022  https://www.geeksforgeeks.org/foundation-css-d...     easy  \n2  17 Feb, 2022  https://www.geeksforgeeks.org/top-20-excel-sho...     easy  \n3  17 Feb, 2022  https://www.geeksforgeeks.org/servlet-fetching...     easy  \n4  21 Feb, 2022    https://www.geeksforgeeks.org/suffix-sum-array/     easy  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author_id</th>\n      <th>last_updated</th>\n      <th>link</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5 Best Practices For Writing SQL Joins</td>\n      <td>priyankab14</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/5-best-practices...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Foundation CSS Dropdown Menu</td>\n      <td>ishankhandelwals</td>\n      <td>20 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/foundation-css-d...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Top 20 Excel Shortcuts That You Need To Know</td>\n      <td>priyankab14</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/top-20-excel-sho...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Servlet – Fetching Result</td>\n      <td>nishatiwari1719</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/servlet-fetching...</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Suffix Sum Array</td>\n      <td>rohit768</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/suffix-sum-array/</td>\n      <td>easy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876248
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "(34551, 5)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876445
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create connection string to storage account**\n",
        "\n",
        "The errors will be saved as a file in Azure Blob storage."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accountName=\"shivmlstorage\"\n",
        "accountKey=\"CqwiRcBzBgSaIopT2NeDAGdRdSp9EilVRSUtIEBn6AiKabc2nD5BUGHo8G1DGQhcWCa+QP8qw8ND+ASt0EGz4w==\"\n",
        "connectionString=f\"DefaultEndpointsProtocol=https;AccountName={accountName};AccountKey={accountKey};EndpointSuffix=core.windows.net\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876560
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Values for connection to Azure Cosmos DB**\n",
        "\n",
        "Each row of the dataset will be stored as an item in a container in Azure Cosmos DB."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cosmos import CosmosClient, PartitionKey"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876658
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosmosEndpoint=\"https://shivmlstorage.documents.azure.com:443/\"\n",
        "cosmosKey=\"4K6XRazr5I5SRoXOLZeYyHDuxpRfmjDCjf764Ih35xcZG10DrljpLZg8B86w11O0AGAgewIxt8evACDbGwqjbQ==\"\n",
        "cosmosDatabase=\"gfg-articles\"\n",
        "cosmosContainer=\"gfg-articles\""
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876740
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client=CosmosClient(url=cosmosEndpoint, credential=cosmosKey)\n",
        "database=client.get_database_client(database=cosmosDatabase)\n",
        "gfgArticlesContainer=database.get_container_client(cosmosContainer)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445876837
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scrap text from the URL to get article content**\n",
        "\n",
        "**1.** Create a new column `text` to store the scrapped text using BeautifulSoup.\n",
        "\n",
        "**2.** Define the function to scrap text given the URL as a parameter.\n",
        "\n",
        "**3.** In batches of 1024, use multi-threading to call this function for each row and save the resulted dataframe to a `.csv` file in Azure Blob Container."
      ],
      "metadata": {
        "id": "Zd4cQrZkvA5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "id": "zsaLA04W0_Hy",
        "gather": {
          "logged": 1694445880090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new column to save the scrapped text from the URLs.\n",
        "articles[\"text\"]=\"\"\n",
        "articles.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "                                          title         author_id  \\\n0        5 Best Practices For Writing SQL Joins       priyankab14   \n1                  Foundation CSS Dropdown Menu  ishankhandelwals   \n2  Top 20 Excel Shortcuts That You Need To Know       priyankab14   \n3                     Servlet – Fetching Result   nishatiwari1719   \n4                              Suffix Sum Array          rohit768   \n\n   last_updated                                               link category  \\\n0  21 Feb, 2022  https://www.geeksforgeeks.org/5-best-practices...     easy   \n1  20 Feb, 2022  https://www.geeksforgeeks.org/foundation-css-d...     easy   \n2  17 Feb, 2022  https://www.geeksforgeeks.org/top-20-excel-sho...     easy   \n3  17 Feb, 2022  https://www.geeksforgeeks.org/servlet-fetching...     easy   \n4  21 Feb, 2022    https://www.geeksforgeeks.org/suffix-sum-array/     easy   \n\n  text  \n0       \n1       \n2       \n3       \n4       ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author_id</th>\n      <th>last_updated</th>\n      <th>link</th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5 Best Practices For Writing SQL Joins</td>\n      <td>priyankab14</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/5-best-practices...</td>\n      <td>easy</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Foundation CSS Dropdown Menu</td>\n      <td>ishankhandelwals</td>\n      <td>20 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/foundation-css-d...</td>\n      <td>easy</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Top 20 Excel Shortcuts That You Need To Know</td>\n      <td>priyankab14</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/top-20-excel-sho...</td>\n      <td>easy</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Servlet – Fetching Result</td>\n      <td>nishatiwari1719</td>\n      <td>17 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/servlet-fetching...</td>\n      <td>easy</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Suffix Sum Array</td>\n      <td>rohit768</td>\n      <td>21 Feb, 2022</td>\n      <td>https://www.geeksforgeeks.org/suffix-sum-array/</td>\n      <td>easy</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7FqxSgf1FJ_",
        "outputId": "1e7283a5-c609-49cc-e3d3-be63966802f8",
        "gather": {
          "logged": 1694445880916
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to save the errors occurred while scrapping text.\n",
        "scrapTextErrors={}"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445882173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set timeout.\n",
        "TIMEOUT_SECS=60"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694445882994
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to scrap text.\n",
        "def scrapText(i, link):\n",
        "    try:\n",
        "        page=requests.get(link).text\n",
        "        parser=BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "        # Get the inner HTML of <div class=\"text\"></div> tag. This consists of the main content.\n",
        "        # Instead of recursively finding this tag with the above class name, I'm going iteratively to avoid max recursion errors.\n",
        "        parser=parser.find(\"html\", recursive=False)\n",
        "        parser=parser.find(\"body\", recursive=False)\n",
        "        parser=parser.find(\"div\", id=\"main\", recursive=False)\n",
        "        parser=parser.find(\"div\", id=\"home-page\", recursive=False)\n",
        "        parser=parser.find(\"div\", class_=\"article-page_flex\", recursive=False)\n",
        "        parser=parser.find(\"div\", class_=\"leftBar\", recursive=False)\n",
        "        parser=parser.find(\"div\", class_=\"article--viewer\", recursive=False)\n",
        "        parser=parser.find(\"div\", class_=\"article--viewer_content\", recursive=False)\n",
        "        parser=parser.find(\"div\", class_=\"a-wrapper\", recursive=False)\n",
        "        parser=parser.find(\"article\", recursive=False)\n",
        "        \n",
        "        text=[\"\"]\n",
        "        for tag in parser.find(\"div\", class_=\"text\", recursive=False).contents:\n",
        "            # Ignore all the <div> tags inside <div class=\"text\"></div> as they do not have any\n",
        "            # main content.\n",
        "            if tag.name!=\"div\":\n",
        "                text.append(\" \".join(tag.stripped_strings))\n",
        "        # Return the main content.\n",
        "        return i, \"\\n\".join(text).strip(\"\\n\")\n",
        "    \n",
        "    except Exception as err:\n",
        "        scrapTextErrors[i]={\"link\": link, \"error\": err}\n",
        "    return i, \"\""
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "id": "uc8ghB8KtOAh",
        "gather": {
          "logged": 1694445883695
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Run the above function for all the links using multithreading.\n",
        "# Test for batches.\n",
        "futureResultErrors=[]\n",
        "batchesCount, BATCH_SIZE=0, 1024\n",
        "# Print batch size\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "for batch_start in range(0, articles.shape[0], BATCH_SIZE):\n",
        "    future_to_url={}\n",
        "    batchesCount+=1 # Batch number of the current batch.\n",
        "    countEmptyText=0 # Count of empty `text` in the current batch.\n",
        "    batch_end=batch_start+BATCH_SIZE if batch_start+BATCH_SIZE<articles.shape[0] else articles.shape[0]\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=128) as executor: \n",
        "        for i in range(batch_start, batch_end):\n",
        "            future_to_url[executor.submit(scrapText, i, articles.loc[i, \"link\"])]=i\n",
        "            \n",
        "        for future in as_completed(future_to_url):\n",
        "            try:\n",
        "                i, text=future.result(timeout=TIMEOUT_SECS)\n",
        "                articles.loc[i, \"text\"]=str(text)\n",
        "\n",
        "                # Convert this article to a dictionary and add the `id` as a string.\n",
        "                gfgArticle=articles.loc[i].to_dict()\n",
        "                gfgArticle[\"id\"]=str(i)\n",
        "                # Create an item in Cosmos DB.\n",
        "                gfgArticlesContainer.create_item(gfgArticle)\n",
        "\n",
        "                # If `text` is empty, update count.\n",
        "                if text==\"\":\n",
        "                    countEmptyText+=1\n",
        "            except Exception as err:\n",
        "                futureResultErrors.append(err)\n",
        "    \n",
        "    # Print status.\n",
        "    print(f\"Batch #{batchesCount}: Extracted `text` for {(batch_end-batch_start)-countEmptyText} links\")\n",
        "    # Empty text for this batch.\n",
        "    articles.loc[batch_start:batch_end, \"text\"]=\"\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Batch size: 1024\nBatch #1: Extracted `text` for 1023 links\nBatch #2: Extracted `text` for 1024 links\nBatch #3: Extracted `text` for 1024 links\nBatch #4: Extracted `text` for 1024 links\nBatch #5: Extracted `text` for 1023 links\nBatch #6: Extracted `text` for 1023 links\nBatch #7: Extracted `text` for 1024 links\nBatch #8: Extracted `text` for 1023 links\nBatch #9: Extracted `text` for 1022 links\nBatch #10: Extracted `text` for 1022 links\nBatch #11: Extracted `text` for 1024 links\nBatch #12: Extracted `text` for 1024 links\nBatch #13: Extracted `text` for 1023 links\nBatch #14: Extracted `text` for 1024 links\nBatch #15: Extracted `text` for 1024 links\nBatch #16: Extracted `text` for 1022 links\nBatch #17: Extracted `text` for 1024 links\nBatch #18: Extracted `text` for 1023 links\nBatch #19: Extracted `text` for 1023 links\nBatch #20: Extracted `text` for 1024 links\nBatch #21: Extracted `text` for 1021 links\nBatch #22: Extracted `text` for 1023 links\nBatch #23: Extracted `text` for 1023 links\nBatch #24: Extracted `text` for 1023 links\nBatch #25: Extracted `text` for 1024 links\nBatch #26: Extracted `text` for 1024 links\nBatch #27: Extracted `text` for 1022 links\nBatch #28: Extracted `text` for 1024 links\nBatch #29: Extracted `text` for 1023 links\nBatch #30: Extracted `text` for 1023 links\nBatch #31: Extracted `text` for 1022 links\nBatch #32: Extracted `text` for 1021 links\nBatch #33: Extracted `text` for 1024 links\nBatch #34: Extracted `text` for 759 links\nCPU times: user 1h 45min 26s, sys: 6min 4s, total: 1h 51min 31s\nWall time: 1h 41min 30s\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Save errors to a Blob**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobClient\n",
        "\n",
        "# Add the futureResultErrors to the scrapTextErrors and save to a blob.\n",
        "scrapTextErrors[\"futureResult\"]=futureResultErrors\n",
        "\n",
        "# Converting the values to string.\n",
        "for i, v in scrapTextErrors.items():\n",
        "    scrapTextErrors[i]=str(v)\n",
        "\n",
        "# Writing to blob.\n",
        "blob=BlobClient.from_connection_string(conn_str=connectionString, container_name=\"gfg-articles-errors\", blob_name=\"ScrapTextErrors.json\")\n",
        "blob.upload_blob(json.dumps(scrapTextErrors), overwrite=True)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "{'etag': '\"0x8DBB2E99E6B7F4E\"',\n 'last_modified': datetime.datetime(2023, 9, 11, 17, 7, 45, tzinfo=datetime.timezone.utc),\n 'content_md5': bytearray(b'\\r\\x980\\xe8\\xee\\xc1\\xef\\xed\\xccH\\xfcR\\xac+\\xafE'),\n 'client_request_id': 'ba327966-50c5-11ee-b394-cdddc276a591',\n 'request_id': 'fc9ca73a-901e-009e-6ed2-e458d9000000',\n 'version': '2022-11-02',\n 'version_id': None,\n 'date': datetime.datetime(2023, 9, 11, 17, 7, 45, tzinfo=datetime.timezone.utc),\n 'request_server_encrypted': True,\n 'encryption_key_sha256': None,\n 'encryption_scope': None}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1694452075068
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above errors occurred because those links do not have any content."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSztwXH+1bB2Q16wguXXUm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}