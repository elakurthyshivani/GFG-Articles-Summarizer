{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e861f4-dbe9-4a7b-8a90-88ea827af470",
   "metadata": {},
   "source": [
    "# **TFIDF Vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d06db-2ec7-4111-9fae-1b085b803874",
   "metadata": {},
   "source": [
    "## **Run required Utilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "703db3a2-831a-4758-ae11-bfbe0448644b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run ../utilities/CassandraUtility.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794329a4-b402-4a5a-8824-340283db21de",
   "metadata": {},
   "source": [
    "## **Read database from Keyspaces using PySpark**\n",
    "\n",
    "**1.** Download the required jar files (`spark-cassandra-connector_2.12-3.3.0.jar, spark-cassandra-connector-assembly_2.12-3.3.0.jar`).\n",
    "\n",
    "**2.** Download your `cassandra_truststore.jks` file.\n",
    "\n",
    "**3.** Create `application.conf` file.\n",
    "\n",
    "**4.** Create `SparkSession` and set the configuration to connect to Keyspaces using service-specific credentials.\n",
    "\n",
    "**5.** Read all rows from `BasicPreprocessedGFGArticles` table, `GFGArticles` keyspace into PySpark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e242bf11-34f1-4661-9a33-e7bf425ad3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6c840f-1b28-466d-869e-f8086fe9fb10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/27 02:37:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark=createSparkSessionWithCassandraConf(\"TFIDFVectorizer\")\n",
    "# Spark version\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94a47af-b504-49f5-a1a2-7ee57d0454a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/27 02:37:13 WARN CassandraConnectionFactory: Ignoring all programmatic configuration, only using configuration from application.conf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   ID| PreprocessedContent|\n",
      "+-----+--------------------+\n",
      "| 2218|matplotlib highly...|\n",
      "|20243|give string str l...|\n",
      "|17714|c variable always...|\n",
      "|19583|want share interv...|\n",
      "|16870|string basic cove...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "articles=createDataFrameFromTable(spark, \"GFGArticles\", \"BasicPreprocessedGFGArticles\")\n",
    "articles.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7eaaa-df15-4353-afcb-d8c5f7bf6650",
   "metadata": {},
   "source": [
    "## **Convert the preprocessed content into tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eedb2fc3-0382-46b6-a4bb-b8748331a996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aba86b0-ef92-4965-bde3-87c80072f74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   ID| PreprocessedContent|              Tokens|\n",
      "+-----+--------------------+--------------------+\n",
      "|29550|functional progra...|[functional, prog...|\n",
      "|28635|give integer n ta...|[give, integer, n...|\n",
      "|24783|give integer n ar...|[give, integer, n...|\n",
      "|23435|give integer n k ...|[give, integer, n...|\n",
      "| 4382|problem use switc...|[problem, use, sw...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(inputCol=\"PreprocessedContent\", outputCol=\"Tokens\")\n",
    "articles=tokenizer.transform(articles).toDF(\"ID\", \"PreprocessedContent\", \"Tokens\")\n",
    "articles.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af24435-734b-486c-b5e2-04a768450a66",
   "metadata": {},
   "source": [
    "## **HashingTF and IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48d3f38-0363-43cb-a3ee-d8ac86ba1543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc5aa11-44d2-45cf-a4f2-90f889a5bf89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|   ID| PreprocessedContent|              Tokens|            TFVector|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|23474|resizable propert...|[resizable, prope...|(50000,[459,2143,...|\n",
      "| 3531|sometimes require...|[sometimes, requi...|(50000,[480,564,1...|\n",
      "|22273|javascript synchr...|[javascript, sync...|(50000,[573,668,2...|\n",
      "|24847|give non negative...|[give, non, negat...|(50000,[3095,4265...|\n",
      "|23798|non homogeneous p...|[non, homogeneous...|(50000,[453,922,1...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfVec=HashingTF(inputCol=\"Tokens\", outputCol=\"TFVector\", numFeatures=50000)\n",
    "tfArticles=tfVec.transform(articles)\n",
    "tfArticles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d3b375f-df32-4d34-9d20-c90dac5e48d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ID| PreprocessedContent|              Tokens|            TFVector|         TFIDFVector|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|21711|parametric method...|[parametric, meth...|(50000,[572,1195,...|(50000,[572,1195,...|\n",
      "|24672|give two positive...|[give, two, posit...|(50000,[564,1659,...|(50000,[564,1659,...|\n",
      "| 7520|maximum number sq...|[maximum, number,...|(50000,[223,743,1...|(50000,[223,743,1...|\n",
      "|14521|10th september tc...|[10th, september,...|(50000,[440,585,6...|(50000,[440,585,6...|\n",
      "|16910|generator python ...|[generator, pytho...|(50000,[453,666,9...|(50000,[453,666,9...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idfVec=IDF(inputCol=\"TFVector\", outputCol=\"TFIDFVector\")\n",
    "idfVecModel=idfVec.fit(tfArticles)\n",
    "articles=idfVecModel.transform(tfArticles).toDF(\"ID\", \"PreprocessedContent\", \"Tokens\", \"TFVector\", \"TFIDFVector\")\n",
    "articles.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f314cbe-5441-4618-8d6a-adb7dae4d51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = false)\n",
      " |-- PreprocessedContent: string (nullable = true)\n",
      " |-- Tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- TFVector: vector (nullable = true)\n",
      " |-- TFIDFVector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look into the schema\n",
    "articles.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c86083c-3d35-4b2d-ade2-12e5d9e44994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ID', IntegerType(), False), StructField('PreprocessedContent', StringType(), True), StructField('Tokens', ArrayType(StringType(), True), True), StructField('TFVector', VectorUDT(), True), StructField('TFIDFVector', VectorUDT(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into the schema\n",
    "articles.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40322b4-40e5-44fe-a81d-249d444c12c5",
   "metadata": {},
   "source": [
    "## **Transform the `TFIDFVector` into separate columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ba31544-8fc9-406f-8f73-bfadc9cb7901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e50bb8-3d9f-44ea-90ae-b1b30e142ced",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ID| PreprocessedContent|              Tokens|            TFVector|         TFIDFVector|     FeaturesIndices|      FeaturesValues|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|31599|give string conta...|[give, string, co...|(50000,[453,1143,...|(50000,[453,1143,...|[453, 1143, 2037,...|[5, 4, 4, 2, 5, 3...|\n",
      "|14638|primary memory li...|[primary, memory,...|(50000,[417,573,5...|(50000,[417,573,5...|[417, 573, 586, 1...|[4, 8, 23, 3, 6, ...|\n",
      "| 5992|database offer nu...|[database, offer,...|(50000,[261,814,2...|(50000,[261,814,2...|[261, 814, 2093, ...|[4, 4, 8, 3, 1, 6...|\n",
      "|29258|article learn det...|[article, learn, ...|(50000,[564,1652,...|(50000,[564,1652,...|[564, 1652, 1998,...|[3, 2, 20, 2, 22,...|\n",
      "| 7998|give two string x...|[give, two, strin...|(50000,[922,4165,...|(50000,[922,4165,...|[922, 4165, 4265,...|[15, 1, 1, 4, 0, ...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# articles=articles.withColumn(\"FeaturesCount\", udf(lambda tfidfVector : tfidfVector.size, \n",
    "#                                          IntegerType())(col(\"TFIDFVector\")))\n",
    "articles=articles.withColumn(\"FeaturesIndices\", udf(lambda tfidfVector : tfidfVector.indices.tolist(), \n",
    "                                           ArrayType(IntegerType()))(col(\"TFIDFVector\")))\n",
    "articles=articles.withColumn(\"FeaturesValues\", udf(lambda tfidfVector : tfidfVector.values.astype(np.int32).tolist(), \n",
    "                                           ArrayType(IntegerType()))(col(\"TFIDFVector\")))\n",
    "articles.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76493276-326a-4cb0-97fd-d1f1ac5a4d9f",
   "metadata": {},
   "source": [
    "## **Write to a new table in Keyspaces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8334d64-c0da-48dd-acdb-a2326796fcbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff7aef5-c284-4125-9bb4-19d6002ce31a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [33792, 34815] saved to GFGArticles.TFIDFVectorGFGArticles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "saveDataFrameToTable(articles[[\"ID\", \"FeaturesIndices\", \"FeaturesValues\"]], \"GFGArticles\", \"TFIDFVectorGFGArticles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
