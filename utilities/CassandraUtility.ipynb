{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c03ca30-8178-41ee-888d-d7365de7ae98",
   "metadata": {},
   "source": [
    "# **Functions interacting with Amazon Keyspaces**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ea59f-ec3b-4ce8-9ebf-ff8f22561264",
   "metadata": {},
   "source": [
    "## **`createDataFrameFromTable()`**\n",
    "\n",
    "Create a dataframe from an Amazon Keyspaces / Cassandra table.\n",
    "\n",
    "**Params**:\n",
    "\n",
    "- `sparkSession`: `pyspark.sql.SparkSession` variable.\n",
    "\n",
    "- `keyspaceName`: Name of the keyspace in Cassandra / Amazon Keyspaces.\n",
    "\n",
    "- `tableName`: Name of the table in the keyspace.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- PySpark dataframe `pyspark.sql.dataframe.DataFrame` with the contents of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150c92c3-7821-47c0-8132-03836159d12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "830e6b6e-a299-414b-8639-d39cdbb5d6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createDataFrameFromTable(sparkSession : SparkSession, \n",
    "                             keyspaceName : str, \n",
    "                             tableName : str) -> DataFrame:\n",
    "    \n",
    "    try:\n",
    "        return spark.read\\\n",
    "              .format(\"org.apache.spark.sql.cassandra\")\\\n",
    "              .options(table=tableName, keyspace=keyspaceName)\\\n",
    "              .load()\n",
    "    \n",
    "    except Exception as err:\n",
    "        print(f\"Exception : {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03df5ba-1680-45b0-b5f2-9d66c4564ae3",
   "metadata": {},
   "source": [
    "## **`createSparkSessionWithCassandraConf()`**\n",
    "\n",
    "Create a `SparkSession` with configuration required to connect to Amazon Keyspaces / Cassandra.\n",
    "\n",
    "**Params**:\n",
    "\n",
    "- `appName`: Name of the `SparkSession`.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- PySpark Session `pyspark.sql.SparkSession` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b6dbcc-b0f9-4ba5-b09b-6cc9e7039b6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b59b977-3107-42f7-a670-8aac3da2b472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createSparkSessionWithCassandraConf(appName : str) -> SparkSession:\n",
    "    \n",
    "    try:\n",
    "        if len(appName)==0:\n",
    "            print(f\"Error : appName cannot be empty.\")\n",
    "        \n",
    "        spark=SparkSession.builder.appName(appName)\\\n",
    "        .config(\"spark.files\", \"../application.conf\")\\\n",
    "        .config(\"spark.jars\", \"../jar-files/spark-cassandra-connector_2.12-3.3.0.jar,\"\n",
    "                                \"../jar-files/spark-cassandra-connector-assembly_2.12-3.3.0.jar\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "        spark.conf.set(\"spark.cassandra.connection.config.profile.path\", \"application.conf\")\n",
    "        spark.conf.set(\"spark.cassandra.connection.ssl.clientAuth.enabled\", \"true\")\n",
    "        spark.conf.set(\"spark.cassandra.connection.ssl.enabled\", \"true\")\n",
    "        \n",
    "        return spark\n",
    "    \n",
    "    except:\n",
    "        print(f\"Exception : {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd70c84-e970-4141-a0ca-01798db6ee14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **`getSizeOfDataFrame()`**:\n",
    "\n",
    "Amazon Keyspaces does not support COUNT of its table. Get the count of a DataFrame created from an Amazon Keyspace table. Should contain `ID` column with unique integer values.\n",
    "\n",
    "**Params**:\n",
    "\n",
    "- `dataframe`: `pyspark.sql.DataFrame` variable.\n",
    "\n",
    "**Returns**:\n",
    "\n",
    "- Count of the PySpark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292740dc-098b-400b-b4da-cd030591ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3fc01d5-a0d1-4ead-b256-8cd652115832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSizeOfDataFrame(dataframe : DataFrame) -> int:\n",
    "    \n",
    "    try:\n",
    "        return dataframe[[\"ID\"]].filter(dataframe.ID > 0).count()\n",
    "    \n",
    "    except:\n",
    "        print(f\"Exception : {err}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70aaa8c-67c3-44de-a601-8668bb829028",
   "metadata": {},
   "source": [
    "## **`saveDataFrameToTable()`**\n",
    "\n",
    "Saves a dataframe to an Amazon Keyspaces / Cassandra table.\n",
    "\n",
    "**Params**:\n",
    "\n",
    "- `dataframe`: `pyspark.sql.DataFrame` variable. Should contain `ID` column with unique integer values.\n",
    "\n",
    "- `keyspaceName`: Name of the keyspace in Cassandra / Amazon Keyspaces.\n",
    "\n",
    "- `tableName`: Name of the table in the keyspace.\n",
    "\n",
    "- `mode`: Mode of saving the dataframe to the table. Default value is `APPEND`.\n",
    "\n",
    "- `batch_size`: Number of rows to save in each batch. To save the whole dataframe at once, pass the total value. Default value is `1024`.\n",
    "\n",
    "- `verbose`: Display console output. Default value is `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47862e58-322c-427a-b475-e6698501364e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2363a6c-605e-4a6b-8834-120edf27b5fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def saveDataFrameToTable(dataframe : DataFrame, \n",
    "                         keyspaceName : str,\n",
    "                         tableName : str,\n",
    "                         mode : str=\"APPEND\", \n",
    "                         batch_size : int=1024, \n",
    "                         verbose : bool=True) -> None:\n",
    "    \n",
    "    # Invalid batch_size.\n",
    "    if batch_size <= 0:\n",
    "        print(\"Error: batch_size cannot be less than 1\")\n",
    "    \n",
    "    try:\n",
    "        # Get the total count of articles.\n",
    "        NO_OF_ARTICLES=getSizeOfDataFrame(dataframe)\n",
    "        NO_OF_ARTICLES\n",
    "\n",
    "        # Save to table in batches.\n",
    "        for start in range(0, NO_OF_ARTICLES+1, batch_size):\n",
    "            dataframe.filter((dataframe.ID >= start) & (dataframe.ID < start+batch_size))\\\n",
    "                    .write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "                    .options(table=tableName, keyspace=keyspaceName)\\\n",
    "                    .mode(mode)\\\n",
    "                    .save()\n",
    "\n",
    "        if(verbose):\n",
    "            print(f\"Batch [{start}, {start+batch_size-1}] saved to {keyspaceName}.{tableName}.\")\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(f\"Exception : {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c8d17-8c76-417e-8ee4-1efde3f850de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
